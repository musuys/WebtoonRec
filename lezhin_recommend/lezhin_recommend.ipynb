{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c554dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Hannanum\n",
    "from konlpy.utils import pprint\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "lezhin_df = pd.read_csv('레진코믹스.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a427b2c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "\n",
    "num_summary=3\n",
    "\n",
    "class SentenceTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.kkma = Kkma()\n",
    "        self.okt = Okt()\n",
    "        self.stopwords =['이', '있', '하', '것', '들', '그', '되', '수', '이', '보', '않', '없', '나', '사람', '주', '아니', '등', '같',\n",
    "                         '우리', '때', '년', '가', '한', '지', '대하', '오', '말', '일', '그렇', '위하', '때문', '그것', '두', '말하', \n",
    "                         '알', '그러나', '받', '못하', '일', '그런', '또', '문제', '더', '사회', '많', '그리고', '좋', '크', '따르', \n",
    "                         '중', '나오', '가지', '씨', '시키', '만들', '지금', '생각하', '그러', '속', '하나', '집', '살', '모르', '적', \n",
    "                         '월', '데', '자신', '안', '어떤', '내', '내', '경우', '명', '생각', '시간', '그녀', '다시', '이런', '앞', \n",
    "                         '보이', '번', '나', '다른', '어떻', '여자', '개', '전', '들', '사실', '이렇', '점', '싶', '말', '정도', \n",
    "                         '좀', '원', '잘', '통하', '소리', '놓', '레진', '연재', '공개', '독점', '인기', '수도', '없는', '제작', '작가',\n",
    "                         '수상', '작', '수상작', '보고', '고', '해도', '통해', '위해', '귀염둥이', '관계']\n",
    "    def url2sentences(self, url):\n",
    "        article = Article(url, language='ko')\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        sentences = self.kkma.sentences(article.text)\n",
    "        \n",
    "        for idx in range(0, len(sentences)):\n",
    "            if len(sentences[idx]) <= 10:\n",
    "                sentences[idx-1] += (' ' + sentences[idx])\n",
    "                sentences[idx] = ''        \n",
    "        return sentences\n",
    "  \n",
    "    def text2sentences(self, text):\n",
    "        sentences = self.kkma.sentences(text)      \n",
    "        for idx in range(0, len(sentences)):\n",
    "            if len(sentences[idx]) <= 10:\n",
    "                sentences[idx-1] += (' ' + sentences[idx])\n",
    "                sentences[idx] = ''\n",
    "        return sentences\n",
    "\n",
    "    def get_nouns(self, sentences):\n",
    "        nouns = []\n",
    "        for sentence in sentences:\n",
    "            if sentence != '':\n",
    "                nouns.append(' '.join([noun for noun in self.okt.nouns(str(sentence)) \n",
    "                                       if noun not in self.stopwords and len(noun) > 1]))\n",
    "        return nouns\n",
    "\n",
    "\n",
    "class GraphMatrix(object):\n",
    "    def __init__(self):\n",
    "        self.tfidf = TfidfVectorizer()\n",
    "        self.cnt_vec = CountVectorizer()\n",
    "        self.graph_sentence = []\n",
    "    def build_sent_graph(self, sentence):\n",
    "        tfidf_mat = self.tfidf.fit_transform(sentence).toarray()\n",
    "        self.graph_sentence = np.dot(tfidf_mat, tfidf_mat.T)\n",
    "        return self.graph_sentence\n",
    "    def build_words_graph(self, sentence):\n",
    "        cnt_vec_mat = normalize(self.cnt_vec.fit_transform(sentence).toarray().astype(float), axis=0)\n",
    "        vocab = self.cnt_vec.vocabulary_\n",
    "        return np.dot(cnt_vec_mat.T, cnt_vec_mat), {vocab[word] : word for word in vocab}\n",
    "\n",
    "#TextRank\n",
    "class Rank(object):\n",
    "    def get_ranks(self, graph, d=0.85): \n",
    "        A = graph\n",
    "        matrix_size = A.shape[0]\n",
    "        for id in range(matrix_size):\n",
    "            A[id, id] = 0 \n",
    "            link_sum = np.sum(A[:,id])\n",
    "            if link_sum != 0:\n",
    "                A[:, id] /= link_sum\n",
    "            A[:, id] *= -d\n",
    "            A[id, id] = 1\n",
    "        B = (1-d) * np.ones((matrix_size, 1))\n",
    "        ranks = np.linalg.solve(A, B) \n",
    "        return {idx: r[0] for idx, r in enumerate(ranks)}\n",
    "\n",
    "class TextRank(object):\n",
    "    def __init__(self, text):\n",
    "        self.sent_tokenize = SentenceTokenizer()\n",
    "        self.sentences = self.sent_tokenize.text2sentences(text)\n",
    "        \n",
    "        self.nouns = self.sent_tokenize.get_nouns(self.sentences)\n",
    "        \n",
    "        self.graph_matrix = GraphMatrix()\n",
    "        self.sent_graph = self.graph_matrix.build_sent_graph(self.nouns)\n",
    "        self.words_graph, self.idx2word = self.graph_matrix.build_words_graph(self.nouns)\n",
    "\n",
    "        self.rank = Rank()\n",
    "        self.sent_rank_idx = self.rank.get_ranks(self.sent_graph)\n",
    "        self.sorted_sent_rank_idx = sorted(self.sent_rank_idx, key=lambda k: self.sent_rank_idx[k], reverse=True)\n",
    "\n",
    "        self.word_rank_idx = self.rank.get_ranks(self.words_graph)\n",
    "        self.sorted_word_rank_idx = sorted(self.word_rank_idx, key=lambda k: self.word_rank_idx[k], reverse=True)\n",
    "    \n",
    "    def summarize(self, sent_num=3):\n",
    "        summary = []\n",
    "        index=[]\n",
    "        for idx in self.sorted_sent_rank_idx[:sent_num]:\n",
    "            index.append(idx)\n",
    "        index.sort()\n",
    "\n",
    "        for idx in index:\n",
    "            summary.append(self.sentences[idx])\n",
    "        return summary\n",
    "\n",
    "    def keywords(self, word_num=10):\n",
    "        rank = Rank()\n",
    "        rank_idx = rank.get_ranks(self.words_graph)\n",
    "        sorted_rank_idx = sorted(rank_idx, key=lambda k: rank_idx[k], reverse=True)\n",
    "\n",
    "        keywords = []\n",
    "        index=[]\n",
    "        \n",
    "        for idx in sorted_rank_idx[:word_num]:\n",
    "            index.append(idx)\n",
    "\n",
    "        for idx in index:\n",
    "            keywords.append(self.idx2word[idx])\n",
    "\n",
    "        return keywords\n",
    "title_list=[]\n",
    "keyword_list=[]\n",
    "for i in lezhin_df.index:\n",
    "    text = lezhin_df.loc[i, '키워드'] + lezhin_df.loc[i, '스토리']\n",
    "    #print(text)\n",
    "    textrank = TextRank(text)\n",
    "    title_list.append(lezhin_df.loc[i, '제목'])\n",
    "    keyword_list.append(textrank.keywords())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd44ca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_data = pd.DataFrame()\n",
    "web_data['제목'] = title_list\n",
    "web_data['키워드'] = keyword_list\n",
    "web_data.to_csv('레진코믹스_sim.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d33e58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>제목</th>\n",
       "      <th>키워드</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>우리사이느은</td>\n",
       "      <td>['로맨스', '연인', '모두', '원색', '파스텔', '사이', '시작', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>아기가 생겼어요</td>\n",
       "      <td>['결혼', '로맨스', '희원', '아기', '아슬아슬', '이자', '아빠', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>애프터 커튼콜</td>\n",
       "      <td>['연극', '매체', '영상', '뮤지컬', '또한', '모든', '이의', '이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>대표님의 삐뚤어진 사랑 [연재]</td>\n",
       "      <td>['집착', '계약', '강재', '원래', '조여', '주변인', '분투', '영...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>너와 사는 오늘</td>\n",
       "      <td>['원영', '연애', '교내', '도희', '라이', '로맨스', '삼각', '소...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>대표님, 사모님이 도망가요</td>\n",
       "      <td>['과연', '그때', '남자', '모든', '불행', '요구', '행운', '가족...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>LOVE WINS</td>\n",
       "      <td>['독자', '동성혼', '소식', '정신', '취해', '해지', '혼인신고', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>사랑할 수 없는 그녀</td>\n",
       "      <td>['꽁꽁', '남동생', '리기', '시작', '시절', '이웃집', '재회', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>우리 내일 이혼해요</td>\n",
       "      <td>['이혼', '갑자기', '고모', '여름', '제안', '집착', '하리', '결...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>안나 이야기</td>\n",
       "      <td>['대장간', '드라마', '로맨스', '모험', '도적', '단골', '로부터',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 제목  \\\n",
       "0           0             우리사이느은   \n",
       "1           1           아기가 생겼어요   \n",
       "2           2            애프터 커튼콜   \n",
       "3           3  대표님의 삐뚤어진 사랑 [연재]   \n",
       "4           4           너와 사는 오늘   \n",
       "5           5     대표님, 사모님이 도망가요   \n",
       "6           6          LOVE WINS   \n",
       "7           7        사랑할 수 없는 그녀   \n",
       "8           8         우리 내일 이혼해요   \n",
       "9           9             안나 이야기   \n",
       "\n",
       "                                                 키워드  \n",
       "0  ['로맨스', '연인', '모두', '원색', '파스텔', '사이', '시작', '...  \n",
       "1  ['결혼', '로맨스', '희원', '아기', '아슬아슬', '이자', '아빠', ...  \n",
       "2  ['연극', '매체', '영상', '뮤지컬', '또한', '모든', '이의', '이...  \n",
       "3  ['집착', '계약', '강재', '원래', '조여', '주변인', '분투', '영...  \n",
       "4  ['원영', '연애', '교내', '도희', '라이', '로맨스', '삼각', '소...  \n",
       "5  ['과연', '그때', '남자', '모든', '불행', '요구', '행운', '가족...  \n",
       "6  ['독자', '동성혼', '소식', '정신', '취해', '해지', '혼인신고', ...  \n",
       "7  ['꽁꽁', '남동생', '리기', '시작', '시절', '이웃집', '재회', '...  \n",
       "8  ['이혼', '갑자기', '고모', '여름', '제안', '집착', '하리', '결...  \n",
       "9  ['대장간', '드라마', '로맨스', '모험', '도적', '단골', '로부터',...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "data = pd.read_csv('레진코믹스_sim.csv', low_memory=False)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6d6b434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF 행렬 : (1240, 3918)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(data['키워드'])\n",
    "print('TF-IDF 행렬 :',tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e9c504a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코사인 유사도 행렬: (1240, 1240)\n",
      "[[1.         0.00966836 0.         ... 0.01816084 0.         0.        ]\n",
      " [0.00966836 1.         0.06915898 ... 0.01586295 0.         0.        ]\n",
      " [0.         0.06915898 1.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.01816084 0.01586295 0.         ... 1.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         1.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(data['키워드'])\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "print('코사인 유사도 행렬:',cosine_sim.shape)\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc4842ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title_to_index = dict(zip(data['제목'], data.index))\n",
    "\n",
    "index = title_to_index['부마님 거기 있어줄래요']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5be8fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "def get_recommendations(text, cosine_sim=cosine_sim):\n",
    "    index = title_to_index[text]\n",
    "\n",
    "    sim = sorted(list(enumerate(cosine_sim[index])), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    web_indices = [index[0] for index in sim[1:6]]\n",
    "    \n",
    "    print(data['제목'].iloc[web_indices])\n",
    "    print(str(cosine_sim[index][web_indices]))\n",
    "\n",
    "# 코사인 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8471e7f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438       황자님 거기 있어 줄래요\n",
      "608           공주님 마음대로!\n",
      "218     로젠 블러드 ~배덕의 저택~\n",
      "116    환생하여 의녀가 되다 [연재]\n",
      "314           공주전쟁 [연재]\n",
      "Name: 제목, dtype: object\n",
      "[0.28261898 0.12906286 0.12116387 0.11590916 0.11003447]\n"
     ]
    }
   ],
   "source": [
    "get_recommendations('부마님 거기 있어줄래요')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
