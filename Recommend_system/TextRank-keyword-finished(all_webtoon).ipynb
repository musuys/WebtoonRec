{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "67410edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#키워드 추출할 파일선택\n",
    "webtoon_df = pd.read_csv('네이버웹툰_완결.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3c01a61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:23: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:23: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_51056/2214737341.py:23: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if sentence is not '':\n"
     ]
    }
   ],
   "source": [
    "class SentenceTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.kkma = Kkma() \n",
    "        self.okt = Okt()\n",
    "        #불용어사전 추가중\n",
    "        with open('C:/Users/user/CodingWorkspace/stopwords.txt', 'r') as f:\n",
    "            list_file = f.readlines()\n",
    "        self.stopwords = list_file[0].split(\",\")\n",
    "        \n",
    "    #text를 입력받아 Kkma.sentences()를 이용해 문장단위로 나눈 뒤 sentences로 리턴\n",
    "    def text2sentences(self, text):  \n",
    "        sentences = self.kkma.sentences(text)\n",
    "        for idx in range(0, len(sentences)):\n",
    "            if len(sentences[idx]) <= 10:\n",
    "                sentences[idx-1] += (' ' + sentences[idx])\n",
    "                sentences[idx] = ''\n",
    "        #text일 때 문장별로 리스트 만듦\n",
    "        return sentences\n",
    "    \n",
    "    def get_nouns(self, sentences):\n",
    "        nouns = []\n",
    "        for sentence in sentences:\n",
    "            if sentence is not '':\n",
    "                nouns.append(' '.join([noun for noun in self.okt.nouns(str(sentence))\n",
    "                                      if noun not in self.stopwords and len(noun) >1])) # 한글자 제거\n",
    "        return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cd38c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMatrix(object):\n",
    "    def __init__(self):\n",
    "        self.tfidf = TfidfVectorizer()\n",
    "        self.cnt_vec = CountVectorizer()\n",
    "        self.graph_sentence = []\n",
    "\n",
    "    def build_words_graph(self, sentence):\n",
    "        cnt_vec_mat = normalize(self.cnt_vec.fit_transform(sentence).toarray().astype(float), axis=0)\n",
    "        vocab = self.cnt_vec.vocabulary_\n",
    "        return np.dot(cnt_vec_mat.T, cnt_vec_mat), {vocab[word] : word for word in vocab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "90039b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rank(object):\n",
    "    \n",
    "    def get_ranks(self, graph, d=0.85): \n",
    "        A = graph\n",
    "        matrix_size = A.shape[0]\n",
    "        for id in range(matrix_size):\n",
    "            A[id, id] = 0 \n",
    "            link_sum = np.sum(A[:,id]) \n",
    "            if link_sum != 0:\n",
    "                A[:, id] /= link_sum\n",
    "            A[:, id] *= -d\n",
    "            A[id, id] = 1\n",
    "\n",
    "        B = (1-d) * np.ones((matrix_size, 1))\n",
    "        ranks = np.linalg.solve(A, B) \n",
    "        return {idx: r[0] for idx, r in enumerate(ranks)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c2f9d50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRank(object):\n",
    "    def __init__(self, text):\n",
    "        self.sent_tokenize = SentenceTokenizer()\n",
    "        self.sentences = self.sent_tokenize.text2sentences(text)\n",
    "        \n",
    "        self.nouns = self.sent_tokenize.get_nouns(self.sentences)\n",
    "        \n",
    "        self.graph_matrix = GraphMatrix()\n",
    "        self.words_graph, self.idx2word = self.graph_matrix.build_words_graph(self.nouns)\n",
    "\n",
    "        self.rank = Rank()\n",
    "        self.word_rank_idx = self.rank.get_ranks(self.words_graph)\n",
    "        self.sorted_word_rank_idx = sorted(self.word_rank_idx, key=lambda k: self.word_rank_idx[k], reverse=True)\n",
    "        \n",
    "        # 키워드 수 조정\n",
    "    def keywords(self, word_num=5):\n",
    "        rank = Rank()\n",
    "        rank_idx = rank.get_ranks(self.words_graph)\n",
    "        sorted_rank_idx = sorted(rank_idx, key=lambda k: rank_idx[k], reverse=True)\n",
    "\n",
    "        keywords = []\n",
    "        index=[]\n",
    "\n",
    "        ######################\n",
    "        for idx in sorted_rank_idx[:word_num]:\n",
    "            index.append(idx)\n",
    "\n",
    "        #index.sort()\n",
    "        for idx in index:\n",
    "            keywords.append(self.idx2word[idx])\n",
    "\n",
    "        return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f89ab3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#크롤링한 csv파일에서 추출\n",
    "title_list=[]\n",
    "keyword_list=[]\n",
    "\n",
    "#장르+스토리에서 키워드뽑기\n",
    "for i in webtoon_df.index:\n",
    "    text =webtoon_df.loc[i, '장르']+webtoon_df.loc[i, '스토리']\n",
    "    \n",
    "    #print(text)\n",
    "    textrank = TextRank(text)\n",
    "    \n",
    "    title_list.append(webtoon_df.loc[i, '제목'])\n",
    "    keyword_list.append(textrank.keywords())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "62f3dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_data = pd.DataFrame()\n",
    "web_data['제목'] = title_list\n",
    "web_data['키워드'] = keyword_list\n",
    "web_data.to_csv('네이버_완결_keyword.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7cdeb458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>제목</th>\n",
       "      <th>키워드</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>파이어스</td>\n",
       "      <td>['공익', '근무', '나방', '액션', '이야기']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>바로 보지 않는</td>\n",
       "      <td>['필요', '희진', '감치', '결심', '드라마']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>인간졸업</td>\n",
       "      <td>['드라마', '라면', '세상', '영재', '소경']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>불어오는 밤</td>\n",
       "      <td>['가문', '동해', '원수', '파발', '불명']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>배틀트레인</td>\n",
       "      <td>['발전', '배틀', '스포츠', '지하철', '토너먼트']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>장난감</td>\n",
       "      <td>['인생', '방식', '분풀이', '비밀', '세상']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[영화원작] 모럴센스</td>\n",
       "      <td>['로맨스', '아주', '남자', '사이', '오해']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>후작님을 녹이는 방법</td>\n",
       "      <td>['얼굴', '결혼', '후작', '에이', '프레이']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2022 서브병에 빠지다!</td>\n",
       "      <td>['서브', '개그', '로맨스', '매력', '발산']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>강림전기 개정기</td>\n",
       "      <td>['액션', '차지', '얼굴', '우등', '강림']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              제목                                 키워드\n",
       "0           0            파이어스     ['공익', '근무', '나방', '액션', '이야기']\n",
       "1           1        바로 보지 않는     ['필요', '희진', '감치', '결심', '드라마']\n",
       "2           2            인간졸업     ['드라마', '라면', '세상', '영재', '소경']\n",
       "3           3          불어오는 밤      ['가문', '동해', '원수', '파발', '불명']\n",
       "4           4           배틀트레인  ['발전', '배틀', '스포츠', '지하철', '토너먼트']\n",
       "5           5             장난감     ['인생', '방식', '분풀이', '비밀', '세상']\n",
       "6           6     [영화원작] 모럴센스     ['로맨스', '아주', '남자', '사이', '오해']\n",
       "7           7     후작님을 녹이는 방법     ['얼굴', '결혼', '후작', '에이', '프레이']\n",
       "8           8  2022 서브병에 빠지다!     ['서브', '개그', '로맨스', '매력', '발산']\n",
       "9           9        강림전기 개정기      ['액션', '차지', '얼굴', '우등', '강림']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "data = pd.read_csv('네이버_완결_keyword.csv', low_memory=False)\n",
    "data.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
